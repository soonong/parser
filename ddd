import requests
from bs4 import BeautifulSoup
import json
import time
import openpyxl as openpyxl
import pandas as pd
openpyxl


def crawl(num):
    url = "http://m.keca.or.kr/service/service07.do?menuCd=4051&currentPageNo={}" \
          "&license=&gubun=page&searchSido=&searchGubun=company&searchText=&CSRFToken=92d2be8b-4d72-419a-a4cd-a21f70a8bd04".format(num)
    data = requests.get(url)
    result = data.content
    return result

links = []

def parse(pageString):
    time.sleep(0.5)
    bsObj = BeautifulSoup(pageString,"html.parser")
    div = bsObj.find("div",{"class":"userList"})
    lis = div.findAll('li')
    for li in lis:
        link = li.find('a')['onclick'].replace("javascript:js_detailAction('","").replace("');","")
        links.append(link)
    return links



def save(filename):  # 파라미터filename 가 파일명 불러오기 코드에는 안먹히네?
    file = open("./filename.json", "w+")
    file.write(json.dumps(filename))

    file = open("./filename.json", "w+")
    df = pd.read_json('./filename.json')
    df.to_excel('filename.xlsx', sheet_name='sheet1')



# codes = []
for num in range(1,999):
    pageString = crawl(num)
    lists = parse(pageString)
    # codes.append(lists)

save(links)
